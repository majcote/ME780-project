\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false,hidelinks]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{ Semantic Segmentation for Unnamed Surface Vessle Navigation}

\author{Martin Cote\\
ME780 Perception For Autonomous Driving\\
University of Waterloo\\
{\tt\small m4cote@uwaterloo.ca}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% INTRODUCTION
%This section introduces your problem, and the overall
%plan for approaching your problem.

\section{Introduction}
For my final project in ME780, I plan to address the task of semantic segmentation
for the use of autonomous navigation of an unmanned surface vessel (USV). I will be 
doing pixel wise classifications of images from a camera mounted to the USV. For the
purpose of this project, I will only require 2 classes, water and other. This task
has several useful applications for the marine industry, such as remote surveys. Classifications
of open water is a part of the full stack required to do safe marine autonomy,
similar to classifying drivable roads in autonomous driving applications. This report
will discuss the proposed strategy to be implemented, as well as the current progress 
to this date.

%-------------------------------------------------------------------------
%%%%%%%%% PROBLEM STATEMENT
%Describe your problem precisely specifying the
%dataset to be used, expected results and evaluation.

\section{Problem Statement }
This project is largely motivated by future projects from my place of employment.
I work for Clearpath robotics, in the research solutions department. We build 
custom robots for the use in robotics research. However we are now looking
towards the remote survey industry, that is, using robotics to remotely survey
environments that are too dirty, dull or dangerous for humans. One such task is 
remote marine surveys, wherein a USV is used to collect data from a body of water
while the operator can stay safely on shore. Clearly a very important part of this
task is to determine if the USV has clear water ahead of it, or it will risk 
running aground.

I therefore propose to use concepts discussed in ME780, Perception For Autonomous Driving,
and adapt them for use on a marine vehicle in bodies of water. My goal for this project
is to implement a convolution neural network to make pixel wise classification of an image
from an onboard camera as either "water" or "other". To the best of my knowledge, there is no
dataset publicly available to be used for this task, therefore a large portion of my project will be
collecting and preparing data to be used for training, testing and evaluation of my network. 
My network will be evaluated on both run time and accuracy, however as the intent is to do
live on board semantic segmentation, minimizing runtime will be prioritised. I expect this
implementation to be able to do classifications with sufficient level of accuracy, however
minimizing the runtime to be able to do live classifications may be more challenging.


%-------------------------------------------------------------------------
%%%%%%%%% Technical approach
%Describe the methods you intend to apply to
%solve the given problem.

\section{Technical Approach}
\subsection{Data Collection}
As previously mentioned, there is no publicly available dataset for use in a marine
environment to the best of my knowledge, therefore the first part of this project
will be collecting such a dataset! To do so, I'll be using Clearpath Robotics's
Heron platform with an onboard Point Grey Chameleon camera as shown in ~\ref{fig:heron}

\begin{figure}[h]	
\begin{center}
  \includegraphics[width=1.0\linewidth]{heron.JPG}
\end{center}
   \caption{Clearpath Robotics's Heron with mounted Camera for marine data collection}
\label{fig:heron}
\end{figure}


The data will be collected in a ROS bag, along with other important ROS topics that may be used
for later stages on the project. The ROS topic \verb|camera\image_color|, will be extracted and 
converted into a mp4 file using the \verb|bag_tools| ROS package ~\cite{bagtools}. PNG images
will then be extracted from the mp4 files at a rate of once every 2 seconds. Repetitive frames
with similar features will be removed.


\subsection{Data Preperations}
Once the images have been collected, they must now be prepared for use with the neural network.
The images must be labelled at a pixel level as either "water" or "other". To simplify classification,
the images will be cropped to remove static portions of the images that do not need to be classified,
such as the outline of the boat itself.

The images will be labelled using the \verb|js-segment-annotator| tool that was developed for related
segmentations work ~\cite{tangseng2017looking}. The result will be a PNG image with different 
RGB values for each class (the difference is subtle, and not visible to the human eye)

The last step will be to implement data augmentation techniques. The number of images in the 
dataset will be limited, therefore color jitter and image flipping will be used to increase the total 
number of images.

\subsection{Segmentation}
For the task of segmentation, I will be using a convolution neural network based on the work
done for SegNet ~\cite{DBLP:journals/corr/KendallBC15} ~\cite{DBLP:journals/corr/BadrinarayananK15}
along with initial parameter weights from previously trained networks.


%-------------------------------------------------------------------------
%%%%%%%%% Preliminary Results
%State and evaluate your results
%upto the milestone.
\section{Preliminary Results}

\subsection{Data collection}
Unfortunately data collection was slightly delayed due to hardware issues, however these were
ultimately resolved and the USV was brought to working state for data collection as shown in figure 
~\ref{fig:heron}. A waterproof enclosure was 3D printed for the Point Grey Chameleon camera, and connected
to the onboard PC through USB, the ROS Point Grey Camera drivers~\cite{PointGreyDrivers} were used. An
external hardrive was used to store the ROS bags as they were recorded. At this time, data was collected from
one large lake, and two smaller storm water ponds in the Waterloo region. This resulted in 184 image total.
I anticipate more images will be required, however I was not able to collect more before the time of this
report due to unfavourable weather. 

\subsection{Data preperation}
The camera topic from the ROS bag was then converted into mp4 files with little difficulty. There were some
errors in the upstream branch of \verb|srv_tools|, however the fixes can be found on my own fork of the
 repo.~\cite{srvtoolsfork}. Image files were then extracted as png files using the \verb|ffmpeg| tool. 
 These images were then cropped to remove static information such as the Heron's own body, as this was not
 required during classification. An example of this can been seen in figure~\ref{fig:crop}.

It was now time for the most time consuming task, labelling all the images! As mentioned previously, an
open sourced tool was used ~\cite{tangseng2017looking}, this tool was fairly easy to use, and only required
a few configurations changes to work for my applications. As you can see from figure ~\ref{fig:tool}, two
classes were used, "water" and "other". The result is a series of images with RBG values corresponding to
different classes. All pictures have now been labelled, and are hosted on my GitHub page.

\subsection{SegNet}
Unfortunately due to delays with hardware, not much progress has yet been done on using the labelled images
in an implementation of SegNet, however I have been successful in setting up my caffee environment on my
home desktop, and now that the images are labelled, I will start working with SegNet shortly.

\begin{figure}[t]	
\begin{center}
  \includegraphics[width=1.0\linewidth]{CL_0025.png}
  \includegraphics[width=1.0\linewidth]{CL_0025C.png}
\end{center}
   \caption{Image was cropped to remove static information such as the USV itself}
\label{fig:crop}
\end{figure}

\begin{figure*}	
\begin{center}
  \includegraphics[width=1.0\linewidth]{segmenttool.png}
\end{center}
   \caption{Screen shot of annotation tool used, where the blue mask corresponds to the water class, and gree is other}
\label{fig:tool}
\end{figure*}

%-------------------------------------------------------------------------

\section{Conclusion}
The goal for my project is to train a convolution neural network for the task of segmentation. To this point,
I have collected my own data, and prepared it for use in SegNet. The next steps will be to implement data augmentation techniques to increase the size of my dataset. Once that is complete, I can start training a
implementation of SegNet with my collected data. In parallel, I'll be collecting more camera data from a 
few more ponds, however now that I've figured the required techniques to prepare the data, I foresee this 
being a much less laborious task than the first collection process.


{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
